{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from scrapy.selector import Selector\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "\n",
    "chromedriver = \"/home/btan/Documents/chromedriver\"\n",
    "# driver = webdriver.Chrome(chromedriver, chrome_options = chrome_options)\n",
    "# driver.close()\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# section 2: determine factors that impact salary\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('./job_openings_2019-05-05.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1093 entries, 0 to 1092\n",
      "Data columns (total 16 columns):\n",
      "job_id              1093 non-null object\n",
      "job_title           1093 non-null object\n",
      "company_name        1093 non-null object\n",
      "company_address     897 non-null object\n",
      "job_category        1093 non-null object\n",
      "job_url             1093 non-null object\n",
      "job_description     914 non-null object\n",
      "job_requirements    789 non-null object\n",
      "employment_type     1093 non-null object\n",
      "seniority           1093 non-null object\n",
      "job_skills          1093 non-null object\n",
      "pay_min             1011 non-null object\n",
      "pay_max             1011 non-null object\n",
      "pay_type            1011 non-null object\n",
      "posting_date        1093 non-null object\n",
      "closing_date        1093 non-null object\n",
      "dtypes: object(16)\n",
      "memory usage: 136.7+ KB\n"
     ]
    }
   ],
   "source": [
    "jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_address</th>\n",
       "      <th>job_category</th>\n",
       "      <th>job_url</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_requirements</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>seniority</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>pay_min</th>\n",
       "      <th>pay_max</th>\n",
       "      <th>pay_type</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>closing_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>JOB-2019-0087098</td>\n",
       "      <td>Associate, Financial Crime Analytics – Transac...</td>\n",
       "      <td>DBS BANK LTD.</td>\n",
       "      <td>MARINA BAY FINANCIAL CENTRE, 12 MARINA BOULEVA...</td>\n",
       "      <td>Banking and Finance</td>\n",
       "      <td>https://www.mycareersfuture.sg/job/associate-f...</td>\n",
       "      <td>Group Legal, Compliance &amp; Secretariat ensur...</td>\n",
       "      <td>Bachelor Degree or any equivalent work experie...</td>\n",
       "      <td>Permanent, Full Time</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>['Business Development', 'Business Strategy', ...</td>\n",
       "      <td>$3,000</td>\n",
       "      <td>$6,000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>24 Apr 2019</td>\n",
       "      <td>24 May 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>JOB-2019-0085156</td>\n",
       "      <td>Pre-sales Consultant - Big Data (5 days, Orcha...</td>\n",
       "      <td>MACHSPEED HUMAN RESOURCES PTE. LTD.</td>\n",
       "      <td>GOLDEN WALL CENTRE, 89 SHORT STREET 188216</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>https://www.mycareersfuture.sg/job/pre-sales-c...</td>\n",
       "      <td>Job Responsibilities</td>\n",
       "      <td>Minimum Degree/Diploma in Computer Science, En...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Professional</td>\n",
       "      <td>['Business Analysis', 'Business Development', ...</td>\n",
       "      <td>$4,000</td>\n",
       "      <td>$5,000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>22 Apr 2019</td>\n",
       "      <td>22 May 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>JOB-2019-0093135</td>\n",
       "      <td>Senior Consultant - Data Migration - AX Dynamics</td>\n",
       "      <td>HCL SINGAPORE PTE. LTD.</td>\n",
       "      <td>AXA TOWER, 8 SHENTON WAY 068811</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>https://www.mycareersfuture.sg/job/senior-cons...</td>\n",
       "      <td>Responsibilities :</td>\n",
       "      <td>5+ years of work experience with minimum 3+ye...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>['Analysis', 'Business Analysis', 'Business De...</td>\n",
       "      <td>$5,500</td>\n",
       "      <td>$8,000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>02 May 2019</td>\n",
       "      <td>01 Jun 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>JOB-2019-0076667</td>\n",
       "      <td>Senior / Data Engineer (Data Science Team)</td>\n",
       "      <td>M1 LIMITED</td>\n",
       "      <td>10 INTERNATIONAL BUSINESS PARK 609928</td>\n",
       "      <td>Engineering, Information Technology, Others, T...</td>\n",
       "      <td>https://www.mycareersfuture.sg/job/senior-data...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor’s degree in Computer Science/Engineer...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Fresh/entry level, Executive, Senior Executive</td>\n",
       "      <td>['Business Analysis', 'Business Intelligence',...</td>\n",
       "      <td>$3,500</td>\n",
       "      <td>$5,800</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>10 Apr 2019</td>\n",
       "      <td>10 May 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>JOB-2019-0092968</td>\n",
       "      <td>AVP, Data Center Manager, Chief Technology Org...</td>\n",
       "      <td>ALEXANDER MANN BPO SOLUTIONS (SINGAPORE) PTE. ...</td>\n",
       "      <td>SGX CENTRE I, 2 SHENTON WAY 068804</td>\n",
       "      <td>Banking and Finance, Information Technology</td>\n",
       "      <td>https://www.mycareersfuture.sg/job/avp-data-ce...</td>\n",
       "      <td>Our purpose as a firm is to make financial liv...</td>\n",
       "      <td>Minimum of 5 years’ experience in a technology...</td>\n",
       "      <td>Permanent, Full Time</td>\n",
       "      <td>Professional</td>\n",
       "      <td>['Cabling', 'Cisco Technologies', 'Cloud Compu...</td>\n",
       "      <td>$8,000</td>\n",
       "      <td>$16,000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>02 May 2019</td>\n",
       "      <td>01 Jun 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               job_id                                          job_title  \\\n",
       "653  JOB-2019-0087098  Associate, Financial Crime Analytics – Transac...   \n",
       "767  JOB-2019-0085156  Pre-sales Consultant - Big Data (5 days, Orcha...   \n",
       "762  JOB-2019-0093135   Senior Consultant - Data Migration - AX Dynamics   \n",
       "181  JOB-2019-0076667         Senior / Data Engineer (Data Science Team)   \n",
       "106  JOB-2019-0092968  AVP, Data Center Manager, Chief Technology Org...   \n",
       "\n",
       "                                          company_name  \\\n",
       "653                                      DBS BANK LTD.   \n",
       "767                MACHSPEED HUMAN RESOURCES PTE. LTD.   \n",
       "762                            HCL SINGAPORE PTE. LTD.   \n",
       "181                                         M1 LIMITED   \n",
       "106  ALEXANDER MANN BPO SOLUTIONS (SINGAPORE) PTE. ...   \n",
       "\n",
       "                                       company_address  \\\n",
       "653  MARINA BAY FINANCIAL CENTRE, 12 MARINA BOULEVA...   \n",
       "767         GOLDEN WALL CENTRE, 89 SHORT STREET 188216   \n",
       "762                    AXA TOWER, 8 SHENTON WAY 068811   \n",
       "181              10 INTERNATIONAL BUSINESS PARK 609928   \n",
       "106                 SGX CENTRE I, 2 SHENTON WAY 068804   \n",
       "\n",
       "                                          job_category  \\\n",
       "653                                Banking and Finance   \n",
       "767                             Information Technology   \n",
       "762                             Information Technology   \n",
       "181  Engineering, Information Technology, Others, T...   \n",
       "106        Banking and Finance, Information Technology   \n",
       "\n",
       "                                               job_url  \\\n",
       "653  https://www.mycareersfuture.sg/job/associate-f...   \n",
       "767  https://www.mycareersfuture.sg/job/pre-sales-c...   \n",
       "762  https://www.mycareersfuture.sg/job/senior-cons...   \n",
       "181  https://www.mycareersfuture.sg/job/senior-data...   \n",
       "106  https://www.mycareersfuture.sg/job/avp-data-ce...   \n",
       "\n",
       "                                       job_description  \\\n",
       "653     Group Legal, Compliance & Secretariat ensur...   \n",
       "767                              Job Responsibilities    \n",
       "762                                 Responsibilities :   \n",
       "181                                                NaN   \n",
       "106  Our purpose as a firm is to make financial liv...   \n",
       "\n",
       "                                      job_requirements       employment_type  \\\n",
       "653  Bachelor Degree or any equivalent work experie...  Permanent, Full Time   \n",
       "767  Minimum Degree/Diploma in Computer Science, En...             Permanent   \n",
       "762   5+ years of work experience with minimum 3+ye...             Permanent   \n",
       "181  Bachelor’s degree in Computer Science/Engineer...             Full Time   \n",
       "106  Minimum of 5 years’ experience in a technology...  Permanent, Full Time   \n",
       "\n",
       "                                          seniority  \\\n",
       "653                                Senior Executive   \n",
       "767                                    Professional   \n",
       "762                                Senior Executive   \n",
       "181  Fresh/entry level, Executive, Senior Executive   \n",
       "106                                    Professional   \n",
       "\n",
       "                                            job_skills pay_min  pay_max  \\\n",
       "653  ['Business Development', 'Business Strategy', ...  $3,000   $6,000   \n",
       "767  ['Business Analysis', 'Business Development', ...  $4,000   $5,000   \n",
       "762  ['Analysis', 'Business Analysis', 'Business De...  $5,500   $8,000   \n",
       "181  ['Business Analysis', 'Business Intelligence',...  $3,500   $5,800   \n",
       "106  ['Cabling', 'Cisco Technologies', 'Cloud Compu...  $8,000  $16,000   \n",
       "\n",
       "    pay_type posting_date closing_date  \n",
       "653  Monthly  24 Apr 2019  24 May 2019  \n",
       "767  Monthly  22 Apr 2019  22 May 2019  \n",
       "762  Monthly  02 May 2019  01 Jun 2019  \n",
       "181  Monthly  10 Apr 2019  10 May 2019  \n",
       "106  Monthly  02 May 2019  01 Jun 2019  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we will be predicting pay with the job description as target,\n",
    "# items with misisng information (e.g. pay) is not very useful\n",
    "\n",
    "\n",
    "# remove items without pay (missing target)\n",
    "jobs.dropna(subset=['pay_min','pay_max','pay_type'], inplace=True)\n",
    "\n",
    "# compute the average pay to be used as our target as there is min/max pay\n",
    "jobs['pay_min'] = jobs['pay_min'].map(lambda x: int(x.replace('$','').replace(',','')))\n",
    "jobs['pay_max'] = jobs['pay_max'].map(lambda x: int(x.replace('$','').replace(',','')))\n",
    "jobs['avg_pay'] = 0.5 * (jobs['pay_min'] + jobs['pay_max'])\n",
    "\n",
    "# as we will be predicting monthly pay, we will convert any annual pay into monthly pay\n",
    "index = jobs[jobs['pay_type']=='Annually'].index \n",
    "for line in index:\n",
    "    jobs.loc[line,'avg_pay'] = int(round(jobs.loc[line,'avg_pay']/12.,0))\n",
    "jobs['avg_pay'] = jobs['avg_pay'].astype(int)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'employment_type' into dummies, remove original column\n",
    "jobs['emp_fulltime'] = jobs['employment_type'].map(lambda x: 1 if 'Full Time' in x else 0)\n",
    "jobs['emp_permanent'] = jobs['employment_type'].map(lambda x: 1 if 'Permanent' in x else 0)\n",
    "jobs['emp_contract'] = jobs['employment_type'].map(lambda x: 1 if 'Contract' in x else 0)\n",
    "jobs['emp_temporary'] = jobs['employment_type'].map(lambda x: 1 if 'Temporary' in x else 0)\n",
    "jobs['emp_freelance'] = jobs['employment_type'].map(lambda x: 1 if 'Freelance' in x else 0)\n",
    "jobs['emp_internship'] = jobs['employment_type'].map(lambda x: 1 if 'Internship' in x else 0)\n",
    "jobs['emp_parttime'] = jobs['employment_type'].map(lambda x: 1 if 'Part Time' in x else 0)\n",
    "\n",
    "jobs.drop(columns='employment_type', inplace=True)\n",
    "\n",
    "# convert the 'seniority' into dummies, remove original column\n",
    "jobs['sen_nonexecutive'] = jobs['seniority'].map(lambda x: 1 if 'Non-executive' in x else 0)\n",
    "jobs['sen_juniorexecutive'] = jobs['seniority'].map(lambda x: 1 if 'Junior Executive' in x else 0)\n",
    "jobs['sen_executive'] = jobs['seniority'].map(lambda x: 1 if 'Executive' in x else 0)\n",
    "jobs['sen_seniorexecutive'] = jobs['seniority'].map(lambda x: 1 if 'Senior Executive' in x else 0)\n",
    "jobs['sen_freshentrylevel'] = jobs['seniority'].map(lambda x: 1 if 'Fresh/entry level' in x else 0)\n",
    "jobs['sen_professional'] = jobs['seniority'].map(lambda x: 1 if 'Professional' in x else 0)\n",
    "jobs['sen_manager'] = jobs['seniority'].map(lambda x: 1 if 'Manager' in x else 0)\n",
    "jobs['sen_middlemanagement'] = jobs['seniority'].map(lambda x: 1 if 'Middle Management' in x else 0)\n",
    "jobs['sen_seniormanagement'] = jobs['seniority'].map(lambda x: 1 if 'Senior Management' in x else 0)\n",
    "\n",
    "jobs.drop(columns='seniority', inplace=True)\n",
    "\n",
    "# convert the 'job_category' into dummies, remove original column\n",
    "jobs['cat_informationtechnology'] = jobs['job_category'].map(lambda x: 1 if 'Information Technology' in x else 0)\n",
    "jobs['cat_engineering'] = jobs['job_category'].map(lambda x: 1 if 'Engineering' in x else 0)\n",
    "jobs['cat_bankingandfinance'] = jobs['job_category'].map(lambda x: 1 if 'Banking and Finance' in x else 0)\n",
    "jobs['cat_adminsecretarial'] = jobs['job_category'].map(lambda x: 1 if 'Admin / Secretarial' in x else 0)\n",
    "jobs['cat_advertisingmedia'] = jobs['job_category'].map(lambda x: 1 if 'Advertising / Media' in x else 0)\n",
    "jobs['cat_consulting'] = jobs['job_category'].map(lambda x: 1 if 'Consulting' in x else 0)\n",
    "jobs['cat_logisticssupplychain'] = jobs['job_category'].map(lambda x: 1 if 'Logistics / Supply Chain' in x else 0)\n",
    "jobs['cat_others'] = jobs['job_category'].map(lambda x: 1 if 'Others' in x else 0)\n",
    "jobs['cat_insurance'] = jobs['job_category'].map(lambda x: 1 if 'Insurance' in x else 0)\n",
    "jobs['cat_generalmanagement'] = jobs['job_category'].map(lambda x: 1 if 'General Management' in x else 0)\n",
    "jobs['cat_scienceslaboratoryrd'] = jobs['job_category'].map(lambda x: 1 if 'Sciences / Laboratory / R&D' in x else 0)\n",
    "jobs['cat_professionalservices'] = jobs['job_category'].map(lambda x: 1 if 'Professional Services' in x else 0)\n",
    "jobs['cat_salesretail'] = jobs['job_category'].map(lambda x: 1 if 'Sales / Retail' in x else 0)\n",
    "jobs['cat_customerservice'] = jobs['job_category'].map(lambda x: 1 if 'Customer Service' in x else 0)\n",
    "jobs['cat_educationandtraining'] = jobs['job_category'].map(lambda x: 1 if 'Education and Training' in x else 0)\n",
    "jobs['cat_publiccivilservice'] = jobs['job_category'].map(lambda x: 1 if 'Public / Civil Service' in x else 0)\n",
    "jobs['cat_accountingauditingtaxation'] = jobs['job_category'].map(lambda x: 1 if 'Accounting / Auditing / Taxation' in x else 0)\n",
    "jobs['cat_riskmanagement'] = jobs['job_category'].map(lambda x: 1 if 'Risk Management' in x else 0)\n",
    "jobs['cat_buildingandconstruction'] = jobs['job_category'].map(lambda x: 1 if 'Building and Construction' in x else 0)\n",
    "jobs['cat_healthcarepharmaceutical'] = jobs['job_category'].map(lambda x: 1 if 'Healthcare / Pharmaceutical' in x else 0)\n",
    "jobs['cat_repairandmaintenance'] = jobs['job_category'].map(lambda x: 1 if 'Repair and Maintenance' in x else 0)\n",
    "jobs['cat_manufacturing'] = jobs['job_category'].map(lambda x: 1 if 'Manufacturing' in x else 0)\n",
    "jobs['cat_design'] = jobs['job_category'].map(lambda x: 1 if 'Design' in x else 0)\n",
    "jobs['cat_telecommunications'] = jobs['job_category'].map(lambda x: 1 if 'Telecommunications' in x else 0)\n",
    "jobs['cat_marketingpublicrelations'] = jobs['job_category'].map(lambda x: 1 if 'Marketing / Public Relations' in x else 0)\n",
    "jobs['cat_humanresources'] = jobs['job_category'].map(lambda x: 1 if 'Human Resources' in x else 0)\n",
    "jobs['cat_hospitality'] = jobs['job_category'].map(lambda x: 1 if 'Hospitality' in x else 0)\n",
    "jobs['cat_fb'] = jobs['job_category'].map(lambda x: 1 if 'F&B' in x else 0)\n",
    "jobs['cat_legal'] = jobs['job_category'].map(lambda x: 1 if 'Legal' in x else 0)\n",
    "jobs['cat_environmenthealth'] = jobs['job_category'].map(lambda x: 1 if 'Environment / Health' in x else 0)\n",
    "jobs['cat_architectureinteriordesign'] = jobs['job_category'].map(lambda x: 1 if 'Architecture / Interior Design' in x else 0)\n",
    "jobs['cat_traveltourism'] = jobs['job_category'].map(lambda x: 1 if 'Travel / Tourism' in x else 0)\n",
    "jobs['cat_generalwork'] = jobs['job_category'].map(lambda x: 1 if 'General Work' in x else 0)\n",
    "jobs['cat_purchasingmerchandising'] = jobs['job_category'].map(lambda x: 1 if 'Purchasing / Merchandising' in x else 0)\n",
    "\n",
    "jobs.drop(columns='job_category', inplace=True)\n",
    "\n",
    "# process the job_skills column -> change from text into a list of skills\n",
    "jobs['job_skillslist'] = jobs['job_skills'].map(lambda x: x[1:-1].replace(\"'\",'').replace(' ','').lower().split(','))\n",
    "# get dummy for the skills\n",
    "\n",
    "cvect = CountVectorizer(stop_words='english')\n",
    "cvect.fit(jobs['job_skills'])\n",
    "X_train = pd.DataFrame(cvect.transform(jobs['job_skills']).todense(),\n",
    "                       columns=cvect.get_feature_names())\n",
    "word_counts = X_train.sum(axis=0)\n",
    "skills = cvect.get_feature_names()\n",
    "# word_counts.sort_values(ascending = False).head(20)\n",
    "\n",
    "jobs.reset_index(drop=True, inplace=True)\n",
    "for row in range(len(jobs)):\n",
    "    for word in skills:\n",
    "        if word in jobs['job_skillslist'][row]:\n",
    "            jobs.loc[row,'skill_{}'.format(word)] = 1\n",
    "        else:\n",
    "            jobs.loc[row,'skill_{}'.format(word)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1006\n",
       "1       5\n",
       "Name: emp_internship, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['emp_internship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1008\n",
       "1       3\n",
       "Name: emp_temporary, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['emp_temporary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1010\n",
       "1       1\n",
       "Name: emp_freelance, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['emp_freelance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1010\n",
       "1       1\n",
       "Name: emp_parttime, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['emp_parttime'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internship, temporary and freelance will affect the pay estimation\n",
    "# since occurance are only a few (1-5) of 1055 entries, \n",
    "# remove the records with flags 'emp_internship', 'emp_temporary', 'emp_freelance'\n",
    "\n",
    "remove_list = jobs[jobs['emp_internship']==1].index\\\n",
    "            .append(jobs[jobs['emp_temporary']==1].index)\\\n",
    "            .append(jobs[jobs['emp_freelance']==1].index)\\\n",
    "            .append(jobs[jobs['emp_parttime']==1].index)\n",
    "jobs.drop(index = remove_list, inplace=True)\n",
    "jobs.drop(columns = ['emp_internship','emp_temporary','emp_freelance','emp_parttime'], inplace=True)\n",
    "jobs.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['job_id', 'job_title', 'company_name', 'company_address',\n",
       "       'job_url', 'job_description', 'job_requirements', 'job_skills',\n",
       "       'pay_min', 'pay_max', 'pay_type', 'posting_date', 'closing_date',\n",
       "       'avg_pay', 'emp_fulltime', 'emp_permanent', 'emp_contract',\n",
       "       'sen_nonexecutive', 'sen_juniorexecutive', 'sen_executive',\n",
       "       'sen_seniorexecutive', 'sen_freshentrylevel', 'sen_professional',\n",
       "       'sen_manager', 'sen_middlemanagement', 'sen_seniormanagement',\n",
       "       'cat_informationtechnology', 'cat_engineering',\n",
       "       'cat_bankingandfinance', 'cat_adminsecretarial',\n",
       "       'cat_advertisingmedia', 'cat_consulting',\n",
       "       'cat_logisticssupplychain', 'cat_others', 'cat_insurance',\n",
       "       'cat_generalmanagement', 'cat_scienceslaboratoryrd',\n",
       "       'cat_professionalservices', 'cat_salesretail',\n",
       "       'cat_customerservice', 'cat_educationandtraining',\n",
       "       'cat_publiccivilservice', 'cat_accountingauditingtaxation',\n",
       "       'cat_riskmanagement', 'cat_buildingandconstruction',\n",
       "       'cat_healthcarepharmaceutical', 'cat_repairandmaintenance',\n",
       "       'cat_manufacturing', 'cat_design', 'cat_telecommunications',\n",
       "       'cat_marketingpublicrelations', 'cat_humanresources',\n",
       "       'cat_hospitality', 'cat_fb', 'cat_legal', 'cat_environmenthealth',\n",
       "       'cat_architectureinteriordesign', 'cat_traveltourism',\n",
       "       'cat_generalwork', 'cat_purchasingmerchandising', 'job_skillslist',\n",
       "       'skill_2g', 'skill_3g', 'skill_5s', 'skill_abap',\n",
       "       'skill_acceptance', 'skill_access', 'skill_account',\n",
       "       'skill_accounting', 'skill_accounts', 'skill_acquisition',\n",
       "       'skill_acquisitions', 'skill_act', 'skill_actionscript',\n",
       "       'skill_active', 'skill_actuarial', 'skill_actuaries',\n",
       "       'skill_administration', 'skill_adobe', 'skill_advertising',\n",
       "       'skill_adwords', 'skill_agile', 'skill_ajax', 'skill_algorithm',\n",
       "       'skill_algorithms', 'skill_alm', 'skill_analysis',\n",
       "       'skill_analytics', 'skill_ansys', 'skill_ant', 'skill_apache',\n",
       "       'skill_application', 'skill_applications', 'skill_appraisal',\n",
       "       'skill_aquatic', 'skill_architectural', 'skill_architecture',\n",
       "       'skill_architectures', 'skill_area', 'skill_art',\n",
       "       'skill_artificial', 'skill_asic', 'skill_asp', 'skill_assay',\n",
       "       'skill_assessment', 'skill_asset', 'skill_assurance',\n",
       "       'skill_audit', 'skill_auditing', 'skill_audits', 'skill_autocad',\n",
       "       'skill_automation', 'skill_automotive', 'skill_av',\n",
       "       'skill_awareness', 'skill_b2b', 'skill_banking', 'skill_basic',\n",
       "       'skill_benefits', 'skill_beverage', 'skill_bgp', 'skill_big',\n",
       "       'skill_biochemistry', 'skill_bioinformatics', 'skill_biology',\n",
       "       'skill_biopharmaceuticals', 'skill_biostatistics',\n",
       "       'skill_biotechnology', 'skill_blogging', 'skill_bloomberg',\n",
       "       'skill_blotting', 'skill_brand', 'skill_branding', 'skill_budgets',\n",
       "       'skill_building', 'skill_business', 'skill_bw', 'skill_cabling',\n",
       "       'skill_cad', 'skill_capital', 'skill_cases', 'skill_cause',\n",
       "       'skill_ccna', 'skill_cell', 'skill_center', 'skill_centered',\n",
       "       'skill_chain', 'skill_change', 'skill_chemistry', 'skill_cisa',\n",
       "       'skill_cisco', 'skill_cissp', 'skill_clearcase', 'skill_climate',\n",
       "       'skill_clinical', 'skill_cloning', 'skill_cloud', 'skill_coaching',\n",
       "       'skill_cobit', 'skill_com', 'skill_commerce', 'skill_commercial',\n",
       "       'skill_commissioning', 'skill_communications', 'skill_community',\n",
       "       'skill_competitive', 'skill_completions', 'skill_compliance',\n",
       "       'skill_comprehensive', 'skill_computer', 'skill_computing',\n",
       "       'skill_concept', 'skill_construction', 'skill_consulting',\n",
       "       'skill_content', 'skill_continuity', 'skill_continuous',\n",
       "       'skill_contract', 'skill_control', 'skill_controls', 'skill_copy',\n",
       "       'skill_copywriting', 'skill_corporate', 'skill_cost', 'skill_cpa',\n",
       "       'skill_creative', 'skill_credit', 'skill_crm', 'skill_cross',\n",
       "       'skill_css', 'skill_culture', 'skill_curriculum', 'skill_customer',\n",
       "       'skill_data', 'skill_database', 'skill_databases', 'skill_db2',\n",
       "       'skill_debugging', 'skill_defect', 'skill_delivery',\n",
       "       'skill_derivatives', 'skill_design', 'skill_detection',\n",
       "       'skill_development', 'skill_devices', 'skill_digital',\n",
       "       'skill_diligence', 'skill_direct', 'skill_direction',\n",
       "       'skill_directory', 'skill_directx', 'skill_disaster',\n",
       "       'skill_discovery', 'skill_distributed', 'skill_distribution',\n",
       "       'skill_dmaic', 'skill_dns', 'skill_documentation',\n",
       "       'skill_dreamweaver', 'skill_drilling', 'skill_drug', 'skill_dss',\n",
       "       'skill_earth', 'skill_ecc', 'skill_eclipse', 'skill_ecology',\n",
       "       'skill_edc', 'skill_editing', 'skill_edition', 'skill_education',\n",
       "       'skill_effects', 'skill_efficiency', 'skill_ehr', 'skill_ejb',\n",
       "       'skill_electrical', 'skill_electronics', 'skill_element',\n",
       "       'skill_email', 'skill_embedded', 'skill_employee',\n",
       "       'skill_employer', 'skill_emr', 'skill_encryption',\n",
       "       'skill_endangered', 'skill_energy', 'skill_engagement',\n",
       "       'skill_engineer', 'skill_engineering', 'skill_english',\n",
       "       'skill_enterprise', 'skill_entrepreneurship',\n",
       "       'skill_environmental', 'skill_epc', 'skill_equities',\n",
       "       'skill_equity', 'skill_erp', 'skill_erwin', 'skill_estate',\n",
       "       'skill_esx', 'skill_etl', 'skill_event', 'skill_excel',\n",
       "       'skill_exchange', 'skill_executive', 'skill_experience',\n",
       "       'skill_external', 'skill_facebook', 'skill_facilities', 'skill_fi',\n",
       "       'skill_field', 'skill_finance', 'skill_financial', 'skill_finite',\n",
       "       'skill_firewalls', 'skill_fixed', 'skill_flash', 'skill_fmcg',\n",
       "       'skill_fmea', 'skill_food', 'skill_forecasting', 'skill_forensics',\n",
       "       'skill_fpga', 'skill_functional', 'skill_fundraising',\n",
       "       'skill_gaap', 'skill_game', 'skill_gameplay', 'skill_games',\n",
       "       'skill_gas', 'skill_gathering', 'skill_gcp', 'skill_general',\n",
       "       'skill_generation', 'skill_genetics', 'skill_git', 'skill_google',\n",
       "       'skill_governance', 'skill_government', 'skill_grant',\n",
       "       'skill_graphic', 'skill_graphics', 'skill_groundwater',\n",
       "       'skill_gsm', 'skill_hardware', 'skill_health', 'skill_healthcare',\n",
       "       'skill_hibernate', 'skill_high', 'skill_higher',\n",
       "       'skill_hospitality', 'skill_hotels', 'skill_hplc', 'skill_hr',\n",
       "       'skill_hris', 'skill_html', 'skill_human', 'skill_hvac',\n",
       "       'skill_ict', 'skill_identity', 'skill_idoc', 'skill_ids',\n",
       "       'skill_ifrs', 'skill_illustration', 'skill_illustrator',\n",
       "       'skill_image', 'skill_immunology', 'skill_impact',\n",
       "       'skill_implementation', 'skill_improvement', 'skill_income',\n",
       "       'skill_indesign', 'skill_industrial', 'skill_industry',\n",
       "       'skill_information', 'skill_infrastructure', 'skill_insight',\n",
       "       'skill_instructional', 'skill_instrumentation', 'skill_insurance',\n",
       "       'skill_integrated', 'skill_integration', 'skill_intelligence',\n",
       "       'skill_interaction', 'skill_interactive', 'skill_interface',\n",
       "       'skill_interior', 'skill_internal', 'skill_international',\n",
       "       'skill_interviews', 'skill_intrusion', 'skill_inventory',\n",
       "       'skill_investment', 'skill_investments', 'skill_invoicing',\n",
       "       'skill_ios', 'skill_ip', 'skill_ips', 'skill_iso', 'skill_itil',\n",
       "       'skill_java', 'skill_javascript', 'skill_jboss', 'skill_jdbc',\n",
       "       'skill_jira', 'skill_journalism', 'skill_jquery', 'skill_json',\n",
       "       'skill_jsp', 'skill_junit', 'skill_kaizen', 'skill_key',\n",
       "       'skill_land', 'skill_language', 'skill_latex', 'skill_layout',\n",
       "       'skill_lead', 'skill_leadership', 'skill_lean', 'skill_learning',\n",
       "       'skill_lecturing', 'skill_ledger', 'skill_lending', 'skill_life',\n",
       "       'skill_lifesciences', 'skill_linux', 'skill_loan', 'skill_loans',\n",
       "       'skill_logistic', 'skill_logistics', 'skill_logo', 'skill_lte',\n",
       "       'skill_lua', 'skill_machine', 'skill_malware', 'skill_managed',\n",
       "       'skill_management', 'skill_managerial', 'skill_manual',\n",
       "       'skill_manufacturing', 'skill_market', 'skill_marketing',\n",
       "       'skill_markets', 'skill_master', 'skill_materials',\n",
       "       'skill_mathematical', 'skill_matlab', 'skill_maven',\n",
       "       'skill_mechanical', 'skill_media', 'skill_mergers',\n",
       "       'skill_methodologies', 'skill_microscopy', 'skill_microsoft',\n",
       "       'skill_microwave', 'skill_migration', 'skill_military',\n",
       "       'skill_mining', 'skill_mixed', 'skill_mm', 'skill_mobile',\n",
       "       'skill_modeling', 'skill_molecular', 'skill_mortgage', 'skill_mpi',\n",
       "       'skill_mrp', 'skill_ms', 'skill_multimedia', 'skill_mysql',\n",
       "       'skill_natural', 'skill_negotiation', 'skill_net',\n",
       "       'skill_netweaver', 'skill_network', 'skill_networking',\n",
       "       'skill_networks', 'skill_new', 'skill_newsletters', 'skill_non',\n",
       "       'skill_nonprofits', 'skill_numerical', 'skill_object',\n",
       "       'skill_objective', 'skill_objects', 'skill_office', 'skill_oil',\n",
       "       'skill_olap', 'skill_omniture', 'skill_onboarding', 'skill_online',\n",
       "       'skill_onshore', 'skill_oop', 'skill_opengl', 'skill_operating',\n",
       "       'skill_operations', 'skill_oracle', 'skill_organizational',\n",
       "       'skill_oriented', 'skill_origination', 'skill_outlook',\n",
       "       'skill_outreach', 'skill_outsourcing', 'skill_oxley',\n",
       "       'skill_parallel', 'skill_partnerships', 'skill_pattern',\n",
       "       'skill_patterns', 'skill_payable', 'skill_payroll', 'skill_pcb',\n",
       "       'skill_pci', 'skill_pcr', 'skill_penetration', 'skill_pensions',\n",
       "       'skill_perforce', 'skill_performance', 'skill_perl',\n",
       "       'skill_permanent', 'skill_personnel', 'skill_petrochemical',\n",
       "       'skill_petroleum', 'skill_pharmaceutical', 'skill_photography',\n",
       "       'skill_photoshop', 'skill_php', 'skill_physics', 'skill_pki',\n",
       "       'skill_pl', 'skill_placement', 'skill_planning', 'skill_plants',\n",
       "       'skill_pmp', 'skill_policies', 'skill_policy', 'skill_portfolio',\n",
       "       'skill_power', 'skill_powerpoint', 'skill_ppap', 'skill_ppc',\n",
       "       'skill_pre', 'skill_predictive', 'skill_pricing', 'skill_prince2',\n",
       "       'skill_private', 'skill_pro', 'skill_process', 'skill_processing',\n",
       "       'skill_procurement', 'skill_product', 'skill_professional',\n",
       "       'skill_profits', 'skill_program', 'skill_programming',\n",
       "       'skill_project', 'skill_protein', 'skill_ps3', 'skill_public',\n",
       "       'skill_purchasing', 'skill_python', 'skill_qtp',\n",
       "       'skill_qualitative', 'skill_quality', 'skill_quantitative',\n",
       "       'skill_quickbooks', 'skill_real', 'skill_receivable',\n",
       "       'skill_recognition', 'skill_reconciliation', 'skill_recovery',\n",
       "       'skill_recruiting', 'skill_recruitment', 'skill_recruitments',\n",
       "       'skill_regression', 'skill_reinsurance', 'skill_relations',\n",
       "       'skill_remediation', 'skill_rendering', 'skill_renewable',\n",
       "       'skill_reporting', 'skill_requirements', 'skill_research',\n",
       "       'skill_resources', 'skill_responsibility', 'skill_restaurants',\n",
       "       'skill_resumes', 'skill_retail', 'skill_retention',\n",
       "       'skill_retrieval', 'skill_revit', 'skill_risk', 'skill_root',\n",
       "       'skill_routers', 'skill_routing', 'skill_saas', 'skill_sales',\n",
       "       'skill_salesforce', 'skill_san', 'skill_sap', 'skill_sapscript',\n",
       "       'skill_sarbanes', 'skill_sas', 'skill_satisfaction',\n",
       "       'skill_scalability', 'skill_science', 'skill_scientific',\n",
       "       'skill_screening', 'skill_scrum', 'skill_sd', 'skill_sdh',\n",
       "       'skill_sdlc', 'skill_search', 'skill_security',\n",
       "       'skill_segmentation', 'skill_selling', 'skill_sem',\n",
       "       'skill_semiconductors', 'skill_seo', 'skill_server',\n",
       "       'skill_servers', 'skill_service', 'skill_services',\n",
       "       'skill_servlets', 'skill_sharepoint', 'skill_sigma',\n",
       "       'skill_signal', 'skill_simulations', 'skill_sketching',\n",
       "       'skill_sketchup', 'skill_soa', 'skill_social', 'skill_software',\n",
       "       'skill_solidworks', 'skill_solution', 'skill_sourcing',\n",
       "       'skill_spc', 'skill_speaking', 'skill_species', 'skill_spring',\n",
       "       'skill_spss', 'skill_sql', 'skill_ssis', 'skill_start',\n",
       "       'skill_statements', 'skill_statistical', 'skill_statistics',\n",
       "       'skill_storage', 'skill_strategic', 'skill_strategy',\n",
       "       'skill_struts', 'skill_studio', 'skill_subversion',\n",
       "       'skill_succession', 'skill_suite', 'skill_supplier',\n",
       "       'skill_supply', 'skill_support', 'skill_sustainability',\n",
       "       'skill_sustainable', 'skill_switches', 'skill_systems',\n",
       "       'skill_talent', 'skill_tax', 'skill_tcp', 'skill_teaching',\n",
       "       'skill_team', 'skill_technical', 'skill_technologies',\n",
       "       'skill_technology', 'skill_telecommunications', 'skill_test',\n",
       "       'skill_testing', 'skill_theory', 'skill_thinking', 'skill_time',\n",
       "       'skill_tomcat', 'skill_tracking', 'skill_training',\n",
       "       'skill_transfer', 'skill_transmission', 'skill_trials',\n",
       "       'skill_troubleshooting', 'skill_tuning', 'skill_typography',\n",
       "       'skill_uml', 'skill_unified', 'skill_unity3d', 'skill_university',\n",
       "       'skill_unix', 'skill_ups', 'skill_urban', 'skill_usability',\n",
       "       'skill_use', 'skill_user', 'skill_validation', 'skill_valuation',\n",
       "       'skill_variance', 'skill_vba', 'skill_vendor', 'skill_verilog',\n",
       "       'skill_video', 'skill_virtualization', 'skill_visio',\n",
       "       'skill_visual', 'skill_vitro', 'skill_vmware', 'skill_volunteer',\n",
       "       'skill_vpn', 'skill_vulnerability', 'skill_wan', 'skill_warehouse',\n",
       "       'skill_warehousing', 'skill_waste', 'skill_water', 'skill_web',\n",
       "       'skill_western', 'skill_wetlands', 'skill_wildlife',\n",
       "       'skill_windows', 'skill_wireless', 'skill_word', 'skill_wordpress',\n",
       "       'skill_work', 'skill_writing', 'skill_xml'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# END OF DATA CLEANING\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Approach 1: Use employment type, seniority and \n",
    "# category to predict salary\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated is on average $740.49 lower than actual.\n",
      "Max: $11000, Min: $-15000, std: $3483.65\n",
      "Accuracy: 0.112957\n"
     ]
    }
   ],
   "source": [
    "# create predictors and target\n",
    "\n",
    "cols = [x for x in jobs.columns.values if ('emp_' in x) | ('sen_' in x) | ('cat_' in x)]\n",
    "X1 = jobs[cols]\n",
    "y1 = jobs['avg_pay']\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
    "\n",
    "logreg1 = LogisticRegression(solver='lbfgs', multi_class='auto').fit(X1_train, y1_train)\n",
    "y1_pred = logreg1.predict(X1_test)\n",
    "y1_error = y1_pred - y1_test\n",
    "highlow = ['higher' if np.mean(y1_error)>0 else 'lower'][0]\n",
    "\n",
    "print('Estimated is on average ${} {} than actual.\\nMax: ${}, Min: ${}, std: ${}'.format(\n",
    "    round(np.abs(np.mean(y1_error)),2), highlow, np.max(y1_error),\n",
    "    np.min(y1_error), round(np.std(y1_error),2)))\n",
    "print('Accuracy: {:.6f}'.format(metrics.accuracy_score(y1_test, y1_pred)) )\n",
    "\n",
    "approach_results = approach_results.append([[1, round(metrics.accuracy_score(y1_test, y1_pred),6), \n",
    "                         round(np.abs(np.mean(y1_error)),2), np.max(y1_error),\n",
    "                         np.min(y1_error), round(np.std(y1_error),2)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Approach 2: Group the data according to low/med/high \n",
    "# salary, then use employment type, seniority and \n",
    "# category to predict salary, use classification\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated for LOW is on average $31.41 higher than actual.\n",
      "Max: $2500.00, Min: $-1750.00, std: $1018.85\n",
      "Accuracy: 0.129630\n",
      "--------------------\n",
      "Estimated for MED is on average $62.81 higher than actual.\n",
      "Max: $1750.00, Min: $-1500.00, std: $819.34\n",
      "Accuracy: 0.212766\n",
      "--------------------\n",
      "Estimated for HIGH is on average $1627.24 lower than actual.\n",
      "Max: $6250.00, Min: $-28500.00, std: $4718.63\n",
      "Accuracy: 0.140000\n",
      "--------------------\n",
      "Overall Estimated is on average $808.35 lower than actual.\n",
      "Max: $6250.00, Min: $-28500.00, std: $3537.75\n",
      "Accuracy: 0.158940\n"
     ]
    }
   ],
   "source": [
    "# create predictors and target\n",
    "\n",
    "cols_x = [x for x in jobs.columns.values if ('emp_' in x) | ('sen_' in x) | ('cat_' in x)]\n",
    "cols_xy = [x for x in jobs.columns.values if ('emp_' in x) | ('sen_' in x) | ('cat_' in x)]\n",
    "cols_xy.append('avg_pay')\n",
    "\n",
    "data2 = jobs[cols_xy]\n",
    "data2['pay_cat'] = pd.qcut(jobs['avg_pay'], 3, labels=['low','medium','high'])\n",
    "\n",
    "# create the predictor and target matrix\n",
    "y2 = data2['avg_pay']\n",
    "X2 = data2.drop(columns='avg_pay')\n",
    "# split them into 3 datasets according to the pay category\n",
    "data2_low = data2[data2['pay_cat']=='low'].drop(columns='pay_cat')\n",
    "data2_med = data2[data2['pay_cat']=='medium'].drop(columns='pay_cat')\n",
    "data2_high = data2[data2['pay_cat']=='high'].drop(columns='pay_cat')\n",
    "\n",
    "## low pay \n",
    "# create predictor and target matrix\n",
    "X2_low = data2_low.iloc[:,:-2]\n",
    "y2_low = data2_low.iloc[:,-1]\n",
    "# create training set and test set\n",
    "X2l_train, X2l_test, y2l_train, y2l_test = train_test_split(X2_low, y2_low, test_size = 0.3, random_state = 42)\n",
    "# fit train data with a logistic regression model\n",
    "logreg2_low = LogisticRegression(solver='lbfgs', multi_class='auto').fit(X2l_train, y2l_train)\n",
    "# predict the test dataset\n",
    "y2l_pred = logreg2_low.predict(X2l_test)\n",
    "# find out the error\n",
    "y2l_error = y2l_pred - y2l_test\n",
    "\n",
    "highlow = ['higher' if np.mean(y2l_error)>0 else 'lower'][0]\n",
    "\n",
    "print('Estimated for LOW is on average ${:.2f} {} than actual.\\nMax: ${:.2f}, Min: ${:.2f}, std: ${:.2f}'.format(\n",
    "    round(np.abs(np.mean(y2l_error)),2), highlow, np.max(y2l_error),\n",
    "    np.min(y2l_error), round(np.std(y2l_error),2)))\n",
    "print('Accuracy: {:.6f}'.format(metrics.accuracy_score(y2l_test, y2l_pred)) )\n",
    "\n",
    "## medium pay\n",
    "# create predictor and target matrix\n",
    "X2_med = data2_med.iloc[:,:-2]\n",
    "y2_med = data2_med.iloc[:,-1]\n",
    "# create training set and test set\n",
    "X2m_train, X2m_test, y2m_train, y2m_test = train_test_split(X2_med, y2_med, test_size = 0.3, random_state = 42)\n",
    "# fit train data with a logistic regression model\n",
    "logreg2_med = LogisticRegression(solver='lbfgs', multi_class='auto').fit(X2m_train, y2m_train)\n",
    "# predict the test dataset\n",
    "y2m_pred = logreg2_med.predict(X2m_test)\n",
    "# find out the error\n",
    "y2m_error = y2m_pred - y2m_test\n",
    "\n",
    "highlow = ['higher' if np.mean(y2m_error)>0 else 'lower'][0]\n",
    "print('-'*20)\n",
    "print('Estimated for MED is on average ${:.2f} {} than actual.\\nMax: ${:.2f}, Min: ${:.2f}, std: ${:.2f}'.format(\n",
    "    round(np.abs(np.mean(y2m_error)),2), highlow, np.max(y2m_error),\n",
    "    np.min(y2m_error), round(np.std(y2m_error),2)))\n",
    "print('Accuracy: {:.6f}'.format(metrics.accuracy_score(y2m_test, y2m_pred)) )\n",
    "\n",
    "## high pay\n",
    "# create predictor and target matrix\n",
    "X2_high = data2_high.iloc[:,:-2]\n",
    "y2_high = data2_high.iloc[:,-1]\n",
    "# create training set and test set\n",
    "X2h_train, X2h_test, y2h_train, y2h_test = train_test_split(X2_high, y2_high, test_size = 0.3, random_state = 42)\n",
    "# fit train data with a logistic regression model\n",
    "logreg2_high = LogisticRegression(solver='lbfgs', multi_class='auto').fit(X2h_train, y2h_train)\n",
    "# predict the test dataset\n",
    "y2h_pred = logreg2_high.predict(X2h_test)\n",
    "# find out the error                          \n",
    "y2h_error = y2h_pred - y2h_test\n",
    "\n",
    "highlow = ['higher' if np.mean(y2h_error)>0 else 'lower'][0]\n",
    "print('-'*20)\n",
    "print('Estimated for HIGH is on average ${:.2f} {} than actual.\\nMax: ${:.2f}, Min: ${:.2f}, std: ${:.2f}'.format(\n",
    "    round(np.abs(np.mean(y2h_error)),2), highlow, np.max(y2h_error),\n",
    "    np.min(y2h_error), round(np.std(y2h_error),2)))\n",
    "print('Accuracy: {:.6f}'.format(metrics.accuracy_score(y2h_test, y2h_pred)) )\n",
    "\n",
    "# find out the overall error: i.e. combine all errors - low med high\n",
    "y2_test_results = pd.concat([pd.Series(y2l_test),\n",
    "                             pd.concat([pd.Series(y2m_test),\n",
    "                                        pd.Series(y2h_test)], axis = 0)\n",
    "                             ], axis = 0)\n",
    "\n",
    "y2_pred_results = pd.concat([pd.Series(y2l_pred),\n",
    "                             pd.concat([pd.Series(y2m_pred),\n",
    "                                        pd.Series(y2h_pred)], axis = 0)\n",
    "                            ], axis = 0)  \n",
    "y2_error = pd.concat([pd.concat([pd.DataFrame(y2l_error, columns=[0]), y2m_error], axis=0), y2h_error], axis=0)[0]\n",
    "\n",
    "highlow = ['higher' if np.mean(y2_error)>0 else 'lower'][0]\n",
    "print('-'*20)\n",
    "print('Overall Estimated is on average ${:.2f} {} than actual.\\nMax: ${:.2f}, Min: ${:.2f}, std: ${:.2f}'.format(\n",
    "    round(np.abs(np.mean(y2_error)),2), highlow, np.max(y2_error),\n",
    "    np.min(y2_error), round(np.std(y2_error),2)))\n",
    "print('Accuracy: {:.6f}'.format(metrics.accuracy_score(y2_test_results, y2_pred_results)) )\n",
    "\n",
    "approach_results = approach_results.append([[2, round(metrics.accuracy_score(y2_test_results, y2_pred_results),6), \n",
    "                         round(np.abs(np.mean(y2_error)),2), np.max(y2_error),\n",
    "                         np.min(y2_error), round(np.std(y2_error),2)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Approach 3: Group the data according to low/med/high \n",
    "# salary, then use employment type, seniority and \n",
    "# category to predict salary, use regression\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated for LOW is on average $27.05 lower than actual.\n",
      "Max: $2427.75, Min: $-1877.60, std: $848.75\n",
      "R2: 0.019657\n",
      "--------------------\n",
      "Estimated for MED is on average $59.29 higher than actual.\n",
      "Max: $3053.47, Min: $-1749.86, std: $675.14\n",
      "R2: -0.417074\n",
      "--------------------\n",
      "Estimated for HIGH is on average $820.97 lower than actual.\n",
      "Max: $4714.61, Min: $-28673.52, std: $4220.75\n",
      "R2: 0.060525\n",
      "--------------------\n",
      "Overall Estimated is on average $394.45 lower than actual.\n",
      "Max: $4714.61, Min: $-28673.52, std: $3097.94\n",
      "R2: 0.604061\n"
     ]
    }
   ],
   "source": [
    "# create predictors and target\n",
    "\n",
    "cols_x = [x for x in jobs.columns.values if ('emp_' in x) | ('sen_' in x) | ('cat_' in x)]\n",
    "cols_xy = [x for x in jobs.columns.values if ('emp_' in x) | ('sen_' in x) | ('cat_' in x)]\n",
    "cols_xy.append('avg_pay')\n",
    "\n",
    "data3 = jobs[cols_xy]\n",
    "data3['pay_cat'] = pd.qcut(jobs['avg_pay'], 3, labels=['low','medium','high'])\n",
    "\n",
    "# create the predictor and target matrix\n",
    "y3 = data3['avg_pay']\n",
    "X3 = data3.drop(columns='avg_pay')\n",
    "# split them into 3 datasets according to the pay category\n",
    "data3_low = data3[data3['pay_cat']=='low'].drop(columns='pay_cat')\n",
    "data3_med = data3[data3['pay_cat']=='medium'].drop(columns='pay_cat')\n",
    "data3_high = data3[data3['pay_cat']=='high'].drop(columns='pay_cat')\n",
    "\n",
    "## low pay \n",
    "# create predictor and target matrix\n",
    "X3_low = data3_low.iloc[:,:-2]\n",
    "y3_low = data3_low.iloc[:,-1]\n",
    "# create training set and test set\n",
    "X3l_train, X3l_test, y3l_train, y3l_test = train_test_split(X3_low, y3_low, test_size = 0.3, random_state = 42)\n",
    "# fit train data with a logistic regression model\n",
    "linreg3_low = LinearRegression().fit(X3l_train, y3l_train)\n",
    "# predict the test dataset\n",
    "y3l_pred = linreg3_low.predict(X3l_test)\n",
    "# find out the error\n",
    "y3l_error = y3l_pred - y3l_test\n",
    "\n",
    "highlow = ['higher' if np.mean(y3l_error)>0 else 'lower'][0]\n",
    "\n",
    "print('Estimated for LOW is on average ${:.2f} {} than actual.\\nMax: ${:.2f}, Min: ${:.2f}, std: ${:.2f}'.format(\n",
    "    round(np.abs(np.mean(y3l_error)),2), highlow, np.max(y3l_error),\n",
    "    np.min(y3l_error), round(np.std(y3l_error),2)))\n",
    "print('R2: {:.6f}'.format(metrics.r2_score(y3l_test, y3l_pred)) )\n",
    "\n",
    "## medium pay\n",
    "# create predictor and target matrix\n",
    "X3_med = data3_med.iloc[:,:-2]\n",
    "y3_med = data3_med.iloc[:,-1]\n",
    "# create training set and test set\n",
    "X3m_train, X3m_test, y3m_train, y3m_test = train_test_split(X3_med, y3_med, test_size = 0.3, random_state = 42)\n",
    "# fit train data with a logistic regression model\n",
    "linreg3_med = LinearRegression().fit(X3m_train, y3m_train)\n",
    "# predict the test dataset\n",
    "y3m_pred = linreg3_med.predict(X3m_test)\n",
    "# find out the error\n",
    "y3m_error = y3m_pred - y3m_test\n",
    "\n",
    "highlow = ['higher' if np.mean(y3m_error)>0 else 'lower'][0]\n",
    "print('-'*20)\n",
    "print('Estimated for MED is on average ${:.2f} {} than actual.\\nMax: ${:.2f}, Min: ${:.2f}, std: ${:.2f}'.format(\n",
    "    round(np.abs(np.mean(y3m_error)),2), highlow, np.max(y3m_error),\n",
    "    np.min(y3m_error), round(np.std(y3m_error),2)))\n",
    "print('R2: {:.6f}'.format(metrics.r2_score(y3m_test, y3m_pred)) )\n",
    "\n",
    "## high pay\n",
    "# create predictor and target matrix\n",
    "X3_high = data3_high.iloc[:,:-2]\n",
    "y3_high = data3_high.iloc[:,-1]\n",
    "# create training set and test set\n",
    "X3h_train, X3h_test, y3h_train, y3h_test = train_test_split(X3_high, y3_high, test_size = 0.3, random_state = 42)\n",
    "# fit train data with a logistic regression model\n",
    "linreg3_high = LinearRegression().fit(X3h_train, y3h_train)\n",
    "# predict the test dataset\n",
    "y3h_pred = linreg3_high.predict(X3h_test)\n",
    "# find out the error\n",
    "y3h_error = y3h_pred - y3h_test\n",
    "\n",
    "highlow = ['higher' if np.mean(y3h_error)>0 else 'lower'][0]\n",
    "print('-'*20)\n",
    "print('Estimated for HIGH is on average ${:.2f} {} than actual.\\nMax: ${:.2f}, Min: ${:.2f}, std: ${:.2f}'.format(\n",
    "    round(np.abs(np.mean(y3h_error)),2), highlow, np.max(y3h_error),\n",
    "    np.min(y3h_error), round(np.std(y3h_error),2)))\n",
    "print('R2: {:.6f}'.format(metrics.r2_score(y3h_test, y3h_pred)) )\n",
    "\n",
    "# find out the overall error: i.e. combine all errors - low med high\n",
    "y3_test_results = pd.concat([pd.Series(y3l_test),\n",
    "                             pd.concat([pd.Series(y3m_test),\n",
    "                                        pd.Series(y3h_test)], axis = 0)\n",
    "                             ], axis = 0)\n",
    "\n",
    "y3_pred_results = pd.concat([pd.Series(y2l_pred),\n",
    "                             pd.concat([pd.Series(y3m_pred),\n",
    "                                        pd.Series(y3h_pred)], axis = 0)\n",
    "                            ], axis = 0)  \n",
    "\n",
    "y3_error = pd.concat([pd.concat([pd.DataFrame(y3l_error, columns=[0]), y3m_error], axis=0), y3h_error], axis=0)[0]\n",
    "\n",
    "\n",
    "highlow = ['higher' if np.mean(y3_error)>0 else 'lower'][0]\n",
    "print('-'*20)\n",
    "print('Overall Estimated is on average ${:.2f} {} than actual.\\nMax: ${:.2f}, Min: ${:.2f}, std: ${:.2f}'.format(\n",
    "    round(np.abs(np.mean(y3_error)),2), highlow, np.max(y3_error),\n",
    "    np.min(y3_error), round(np.std(y3_error),2)))\n",
    "print('R2: {:.6f}'.format(metrics.r2_score(y3_test_results, y3_pred_results)) )\n",
    "\n",
    "approach_results = approach_results.append([[3, round(metrics.r2_score(y3_test_results, y3_pred_results),6), \n",
    "                         round(np.abs(np.mean(y3_error)),2), round(np.max(y3_error),2),\n",
    "                         round(np.min(y3_error),2), round(np.std(y3_error),2)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Approach 4: Use the job requirements data to determine \n",
    "# salary, using the CountVectorizer with MultinomialNB\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275 fields were removed. current dataset contains 727 rows\n",
      "--------------------\n",
      "Best min_df is 5 with a R2_score of 0.159817\n",
      "--------------------\n",
      "Overall Estimated is on average $740.33 lower than actual.\n",
      "Max: $11000.00, Min: $-26000.00, std: $3916.36\n",
      "Accuracy: 0.127854\n"
     ]
    }
   ],
   "source": [
    "# copy out the dataset, drop those rows with empty job requirements\n",
    "\n",
    "X4 = jobs.dropna(subset = ['job_requirements'])\n",
    "print('{} fields were removed. current dataset contains {} rows'.format(\n",
    "        len(jobs)-len(X4), len(X4)))\n",
    "# create predictor and target matrix\n",
    "y4 = X4['avg_pay']\n",
    "X4 = X4['job_requirements']\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.3, random_state=42)\n",
    "\n",
    "# find out the best parameters\n",
    "score = []\n",
    "for min_d in range(1,50):\n",
    "    \n",
    "    cvect = CountVectorizer(stop_words='english', \n",
    "                ngram_range=(1,2), \n",
    "                max_features=10000,\n",
    "                min_df=min_d)\n",
    "    # create document-term matrices\n",
    "    X4_train_dtm = cvect.fit_transform(X4_train)\n",
    "    X4_test_dtm  = cvect.transform(X4_test)\n",
    "\n",
    "    # use MultinomialNB\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X4_train_dtm, y4_train)\n",
    "    y4_pred = mnb.predict(X4_test_dtm)\n",
    "    y4_error = y4_pred - y4_test  \n",
    "    \n",
    "    score.append([min_d, round(metrics.accuracy_score(y4_test, y4_pred),6)])\n",
    "\n",
    "score = pd.DataFrame(score)\n",
    "score.columns = ['min_df','R2_score']\n",
    "\n",
    "best_df = score.loc[score[score['R2_score'] == score['R2_score'].max()].index[0], 'min_df']\n",
    "best_score = score['R2_score'].max()\n",
    "print('-'*20)\n",
    "print('Best min_df is {} with a R2_score of {}'.format(best_df, best_score))\n",
    "\n",
    "## predict using the best parameters\n",
    "\n",
    "# create model\n",
    "model4 = make_pipeline( CountVectorizer(stop_words='english', \n",
    "                        ngram_range=(1,10), \n",
    "                        max_features=1000,\n",
    "                        min_df=best_df),\n",
    "                      \n",
    "                        MultinomialNB()\n",
    "                      )\n",
    "# fit & predict data\n",
    "model4.fit(X4_train, y4_train)\n",
    "y4_pred = model4.predict(X4_test)\n",
    "y4_error = y4_pred - y4_test\n",
    "\n",
    "# present results\n",
    "highlow = ['higher' if np.mean(y4_error)>0 else 'lower'][0]\n",
    "print('-'*20)\n",
    "print('Overall Estimated is on average ${:.2f} {} than actual.\\nMax: ${:.2f}, Min: ${:.2f}, std: ${:.2f}'.format(\n",
    "    round(np.abs(np.mean(y4_error)),2), highlow, np.max(y4_error),\n",
    "    np.min(y4_error), round(np.std(y4_error),2)))\n",
    "print('Accuracy: {:.6f}'.format(metrics.accuracy_score(y4_test, y4_pred)) )\n",
    "\n",
    "approach_results = approach_results.append([[4, round(metrics.accuracy_score(y4_test, y4_pred),6), \n",
    "                         round(np.abs(np.mean(y4_error)),2), np.max(y4_error),\n",
    "                         np.min(y4_error), round(np.std(y4_error),2)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Approach 5: Use the job requirements data to determine \n",
    "# salary, using the CountVectorizer with LogisticRegression\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275 fields were removed. current dataset contains 727 rows\n",
      "--------------------\n",
      "Best min_df is 5 with a R2_score of 0.159817\n",
      "--------------------\n",
      "Overall Estimated is on average $1067.73 lower than actual.\n",
      "Max: $5450.00, Min: $-26000.00, std: $3550.84\n",
      "Accuracy: 0.155251\n"
     ]
    }
   ],
   "source": [
    "# copy out the dataset, drop those rows with empty job requirements\n",
    "\n",
    "X5 = jobs.dropna(subset = ['job_requirements'])\n",
    "print('{} fields were removed. current dataset contains {} rows'.format(\n",
    "        len(jobs)-len(X5), len(X5)))\n",
    "# create predictor and target matrix\n",
    "y5 = X5['avg_pay']\n",
    "X5 = X5['job_requirements']\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5, test_size=0.3, random_state=42)\n",
    "\n",
    "# find out the best parameters\n",
    "score = []\n",
    "for min_d in range(1,50):\n",
    "    \n",
    "    cvect = CountVectorizer(stop_words='english', \n",
    "                ngram_range=(1,2), \n",
    "                max_features=10000,\n",
    "                min_df=min_d)\n",
    "    # create document-term matrices\n",
    "    X5_train_dtm = cvect.fit_transform(X5_train)\n",
    "    X5_test_dtm  = cvect.transform(X5_test)\n",
    "\n",
    "    # use MultinomialNB\n",
    "    mnb = MultinomialNB().fit(X5_train_dtm, y5_train)\n",
    "    y5_pred = mnb.predict(X5_test_dtm)\n",
    "    y5_error = y5_pred - y5_test  \n",
    "    \n",
    "    score.append([min_d, round(metrics.accuracy_score(y5_test, y5_pred),6)])\n",
    "\n",
    "score = pd.DataFrame(score)\n",
    "score.columns = ['min_df','R2_score']\n",
    "\n",
    "best_df = score.loc[score[score['R2_score'] == score['R2_score'].max()].index[0], 'min_df']\n",
    "best_score = score['R2_score'].max()\n",
    "print('-'*20)\n",
    "print('Best min_df is {} with a R2_score of {}'.format(best_df, best_score))\n",
    "\n",
    "## predict using the best parameters\n",
    "\n",
    "# create model\n",
    "model5 = make_pipeline( CountVectorizer(stop_words='english', \n",
    "                        ngram_range=(1,10), \n",
    "                        max_features=1000,\n",
    "                        min_df=best_df),\n",
    "                      \n",
    "                        LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
    "                      )\n",
    "# fit & predict data\n",
    "model5.fit(X5_train, y5_train)\n",
    "y5_pred = model5.predict(X5_test)\n",
    "y5_error = y5_pred - y5_test\n",
    "\n",
    "# present results\n",
    "highlow = ['higher' if np.mean(y5_error)>0 else 'lower'][0]\n",
    "print('-'*20)\n",
    "print('Overall Estimated is on average ${:.2f} {} than actual.\\nMax: ${:.2f}, Min: ${:.2f}, std: ${:.2f}'.format(\n",
    "    round(np.abs(np.mean(y5_error)),2), highlow, np.max(y5_error),\n",
    "    np.min(y5_error), round(np.std(y5_error),2)))\n",
    "print('Accuracy: {:.6f}'.format(metrics.accuracy_score(y5_test, y5_pred)) )\n",
    "\n",
    "approach_results = approach_results.append([[5, round(metrics.accuracy_score(y5_test, y5_pred),6), \n",
    "                         round(np.abs(np.mean(y5_error)),2), np.max(y5_error),\n",
    "                         np.min(y5_error), round(np.std(y5_error),2)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>score</th>\n",
       "      <th>mean_error</th>\n",
       "      <th>min_error</th>\n",
       "      <th>max_error</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.112957</td>\n",
       "      <td>740.49</td>\n",
       "      <td>11000.00</td>\n",
       "      <td>-15000.00</td>\n",
       "      <td>3483.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.158940</td>\n",
       "      <td>808.35</td>\n",
       "      <td>6250.00</td>\n",
       "      <td>-28500.00</td>\n",
       "      <td>3537.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.604061</td>\n",
       "      <td>394.45</td>\n",
       "      <td>4714.61</td>\n",
       "      <td>-28673.52</td>\n",
       "      <td>3097.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.127854</td>\n",
       "      <td>740.33</td>\n",
       "      <td>11000.00</td>\n",
       "      <td>-26000.00</td>\n",
       "      <td>3916.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.155251</td>\n",
       "      <td>1067.73</td>\n",
       "      <td>5450.00</td>\n",
       "      <td>-26000.00</td>\n",
       "      <td>3550.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   approach     score  mean_error  min_error  max_error      std\n",
       "0         1  0.112957      740.49   11000.00  -15000.00  3483.65\n",
       "1         2  0.158940      808.35    6250.00  -28500.00  3537.75\n",
       "2         3  0.604061      394.45    4714.61  -28673.52  3097.94\n",
       "3         4  0.127854      740.33   11000.00  -26000.00  3916.36\n",
       "4         5  0.155251     1067.73    5450.00  -26000.00  3550.84"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approach_results.columns = ['approach','score','mean_error','min_error','max_error','std']\n",
    "approach_results.reset_index(drop=True, inplace=True)\n",
    "approach_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best approach used is approach 3 with an accuracy score of 0.604061. \n",
      "Mean Error: 394.45, Min Error: 4714.61, Max Error: -28673.52, std: 3097.94\n"
     ]
    }
   ],
   "source": [
    "best_approach_index = approach_results[approach_results['score']==approach_results['score'].max()].index[0]\n",
    "print('The best approach used is approach {} with an accuracy score of {}. \\nMean Error: {}, Min Error: {}, Max Error: {}, std: {}'.format(\n",
    "   approach_results.approach[best_approach_index], approach_results['score'][best_approach_index],\n",
    "   approach_results.mean_error[best_approach_index], approach_results.min_error[best_approach_index],\n",
    "   approach_results.max_error[best_approach_index], approach_results['std'][best_approach_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = pd.DataFrame([linreg3_low.coef_])\n",
    "results1.columns = X3l_train.columns.values\n",
    "results1 = results1.transpose()\n",
    "results1.columns = ['coef']\n",
    "results1['abs_coef'] = np.abs(results1['coef'])\n",
    "results1['weightage'] = results1.coef / np.sum(results1.coef)\n",
    "results1['abs_weightage'] = results1.abs_coef / np.sum(results1.abs_coef)\n",
    "# results.sort_values(by='abs_coef', ascending=False)\n",
    "results1.sort_values(by='coef', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 factors that affect pay (in order of importance): \n",
      "['sen_seniormanagement' 'sen_middlemanagement' 'cat_bankingandfinance'\n",
      " 'sen_manager' 'cat_consulting' 'sen_seniorexecutive' 'cat_engineering'\n",
      " 'cat_design' 'sen_professional' 'sen_nonexecutive']\n"
     ]
    }
   ],
   "source": [
    "print('Top 10 factors that affect pay (in order of importance): \\n{}'.format(\n",
    "    results1.head(10).transpose().columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "      <th>weightage</th>\n",
       "      <th>abs_weightage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sen_seniormanagement</th>\n",
       "      <td>1094.718253</td>\n",
       "      <td>1094.718253</td>\n",
       "      <td>-0.118781</td>\n",
       "      <td>0.051477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sen_middlemanagement</th>\n",
       "      <td>955.977089</td>\n",
       "      <td>955.977089</td>\n",
       "      <td>-0.103727</td>\n",
       "      <td>0.044953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_bankingandfinance</th>\n",
       "      <td>749.909475</td>\n",
       "      <td>749.909475</td>\n",
       "      <td>-0.081368</td>\n",
       "      <td>0.035263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sen_manager</th>\n",
       "      <td>604.607810</td>\n",
       "      <td>604.607810</td>\n",
       "      <td>-0.065602</td>\n",
       "      <td>0.028431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_consulting</th>\n",
       "      <td>445.405145</td>\n",
       "      <td>445.405145</td>\n",
       "      <td>-0.048328</td>\n",
       "      <td>0.020944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sen_seniorexecutive</th>\n",
       "      <td>311.872514</td>\n",
       "      <td>311.872514</td>\n",
       "      <td>-0.033839</td>\n",
       "      <td>0.014665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_engineering</th>\n",
       "      <td>304.022500</td>\n",
       "      <td>304.022500</td>\n",
       "      <td>-0.032987</td>\n",
       "      <td>0.014296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_design</th>\n",
       "      <td>257.529361</td>\n",
       "      <td>257.529361</td>\n",
       "      <td>-0.027943</td>\n",
       "      <td>0.012110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sen_professional</th>\n",
       "      <td>242.419047</td>\n",
       "      <td>242.419047</td>\n",
       "      <td>-0.026303</td>\n",
       "      <td>0.011399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sen_nonexecutive</th>\n",
       "      <td>235.601586</td>\n",
       "      <td>235.601586</td>\n",
       "      <td>-0.025564</td>\n",
       "      <td>0.011079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              coef     abs_coef  weightage  abs_weightage\n",
       "sen_seniormanagement   1094.718253  1094.718253  -0.118781       0.051477\n",
       "sen_middlemanagement    955.977089   955.977089  -0.103727       0.044953\n",
       "cat_bankingandfinance   749.909475   749.909475  -0.081368       0.035263\n",
       "sen_manager             604.607810   604.607810  -0.065602       0.028431\n",
       "cat_consulting          445.405145   445.405145  -0.048328       0.020944\n",
       "sen_seniorexecutive     311.872514   311.872514  -0.033839       0.014665\n",
       "cat_engineering         304.022500   304.022500  -0.032987       0.014296\n",
       "cat_design              257.529361   257.529361  -0.027943       0.012110\n",
       "sen_professional        242.419047   242.419047  -0.026303       0.011399\n",
       "sen_nonexecutive        235.601586   235.601586  -0.025564       0.011079"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# section 3: determine factors that distinguish job category\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# section 3a: predicting components of a job posting that \n",
    "# distinguish data scientist from other data jobs\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the \"data scientist\" index and the non 'data scientist' index\n",
    "jobs.reset_index(drop=True, inplace=True)\n",
    "sci_index = jobs[jobs['job_title'].str.contains('Scientist') &\n",
    "                 jobs['job_title'].str.contains('Data')].index\n",
    "non_sci_index = [i for i in jobs.index if i not in sci_index]\n",
    "\n",
    "# copy out the dataframe\n",
    "df3a = jobs.copy()\n",
    "df3a['is_ds'] = 0\n",
    "df3a.loc[sci_index, 'is_ds'] = 1\n",
    "\n",
    "# as the data is inbalanced, we extract an equal number of samples from each class\n",
    "np.random.seed(42)\n",
    "df3a_index = np.append(np.random.choice(sci_index,size=500, replace=True), \n",
    "                       np.random.choice(non_sci_index, size=500, replace=True))\n",
    "# create the balanced dataframe\n",
    "df3a = df3a.loc[df3a_index,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.840000\n",
      "The top 10 characteristics that makes Data Scientist different from others are: \n",
      "['skill_mpi' 'skill_crm' 'skill_spss' 'skill_ssis' 'skill_strategy'\n",
      " 'skill_telecommunications' 'skill_html' 'skill_gcp' 'skill_edc'\n",
      " 'skill_valuation']\n"
     ]
    }
   ],
   "source": [
    "# extract out the columns - skills, and is_ds\n",
    "cols = [i for i in df3a.columns if ( ('skill_' in i) )]\n",
    "# create predictor and target matrix, training set and testing set\n",
    "X3a = df3a[cols]\n",
    "y3a = df3a['is_ds']\n",
    "X3a_train, X3a_test, y3a_train, y3a_test = train_test_split(X3a, y3a, test_size=0.2, random_state=42)\n",
    "# use logistic regression to predict\n",
    "logreg3a = LogisticRegression(solver='lbfgs').fit(X3a_train, y3a_train)\n",
    "y3a_pred = logreg3a.predict(X3a_test)\n",
    "# get accuracy of prediction\n",
    "print('Accuracy: {:.6f}'.format(metrics.accuracy_score(y3a_test, y3a_pred)) )\n",
    "\n",
    "# get the top 10 impactful columns\n",
    "results_3a = pd.DataFrame([logreg3a.coef_[0]], columns=cols).transpose()\n",
    "null_cols = results_3a[results_3a[0]==0].index\n",
    "results_3a = results_3a.transpose()\n",
    "results_3a.drop(columns=null_cols, inplace=True)\n",
    "\n",
    "results_3a = results_3a.transpose()\n",
    "results_3a.columns = ['coef']\n",
    "results_3a['abs_coef'] = np.abs(results_3a.coef)\n",
    "results_3a['weightage'] = results_3a.coef / np.sum(results_3a.coef)\n",
    "results_3a['abs_weightage'] = results_3a.abs_coef / np.sum(results_3a.abs_coef)\n",
    "# results_3a.sort_values(by='abs_weightage', ascending = False, inplace = True )\n",
    "results_3a.sort_values(by='weightage', ascending = False, inplace = True)\n",
    "num_results = 10\n",
    "# print(results_3a.head(num_results))\n",
    "\n",
    "print('The top {} characteristics that makes Data Scientist different from others are: \\n{}'.format(\n",
    "      num_results, results_3a.head(num_results).index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "      <th>weightage</th>\n",
       "      <th>abs_weightage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>skill_mpi</th>\n",
       "      <td>3.088211</td>\n",
       "      <td>3.088211</td>\n",
       "      <td>0.643639</td>\n",
       "      <td>0.039287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_crm</th>\n",
       "      <td>1.634510</td>\n",
       "      <td>1.634510</td>\n",
       "      <td>0.340661</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_spss</th>\n",
       "      <td>1.579409</td>\n",
       "      <td>1.579409</td>\n",
       "      <td>0.329178</td>\n",
       "      <td>0.020093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_ssis</th>\n",
       "      <td>1.500090</td>\n",
       "      <td>1.500090</td>\n",
       "      <td>0.312646</td>\n",
       "      <td>0.019084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_strategy</th>\n",
       "      <td>1.320348</td>\n",
       "      <td>1.320348</td>\n",
       "      <td>0.275185</td>\n",
       "      <td>0.016797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_telecommunications</th>\n",
       "      <td>1.184688</td>\n",
       "      <td>1.184688</td>\n",
       "      <td>0.246911</td>\n",
       "      <td>0.015071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_html</th>\n",
       "      <td>1.103462</td>\n",
       "      <td>1.103462</td>\n",
       "      <td>0.229982</td>\n",
       "      <td>0.014038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_gcp</th>\n",
       "      <td>1.103362</td>\n",
       "      <td>1.103362</td>\n",
       "      <td>0.229961</td>\n",
       "      <td>0.014037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_edc</th>\n",
       "      <td>1.103362</td>\n",
       "      <td>1.103362</td>\n",
       "      <td>0.229961</td>\n",
       "      <td>0.014037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_valuation</th>\n",
       "      <td>1.032028</td>\n",
       "      <td>1.032028</td>\n",
       "      <td>0.215093</td>\n",
       "      <td>0.013129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              coef  abs_coef  weightage  abs_weightage\n",
       "skill_mpi                 3.088211  3.088211   0.643639       0.039287\n",
       "skill_crm                 1.634510  1.634510   0.340661       0.020794\n",
       "skill_spss                1.579409  1.579409   0.329178       0.020093\n",
       "skill_ssis                1.500090  1.500090   0.312646       0.019084\n",
       "skill_strategy            1.320348  1.320348   0.275185       0.016797\n",
       "skill_telecommunications  1.184688  1.184688   0.246911       0.015071\n",
       "skill_html                1.103462  1.103462   0.229982       0.014038\n",
       "skill_gcp                 1.103362  1.103362   0.229961       0.014037\n",
       "skill_edc                 1.103362  1.103362   0.229961       0.014037\n",
       "skill_valuation           1.032028  1.032028   0.215093       0.013129"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_3a.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# section 3b: what features are important for distinguishing\n",
    "# junior vs senior positions\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777 rows with 1 seniority type\n",
      "174 rows with 2 seniority type\n",
      "36 rows with 3 seniority type\n",
      "13 rows with 4 seniority type\n",
      "2 rows with 5 seniority type\n",
      "0 rows with 6 seniority type\n"
     ]
    }
   ],
   "source": [
    "sen_cols = [i for i in jobs.columns if 'sen_' in i]\n",
    "print('{} rows with 1 seniority type'.format(len(jobs[jobs[sen_cols].sum(axis=1)==1])))\n",
    "print('{} rows with 2 seniority type'.format(len(jobs[jobs[sen_cols].sum(axis=1)==2])))\n",
    "print('{} rows with 3 seniority type'.format(len(jobs[jobs[sen_cols].sum(axis=1)==3])))\n",
    "print('{} rows with 4 seniority type'.format(len(jobs[jobs[sen_cols].sum(axis=1)==4])))\n",
    "print('{} rows with 5 seniority type'.format(len(jobs[jobs[sen_cols].sum(axis=1)==5])))\n",
    "print('{} rows with 6 seniority type'.format(len(jobs[jobs[sen_cols].sum(axis=1)==6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 0.703990\n"
     ]
    }
   ],
   "source": [
    "# for ease of classification, we only consider jobs with only 1 seniority type\n",
    "ind = jobs[jobs[sen_cols].sum(axis=1)==1].index\n",
    "df3b = jobs.loc[ind,:]\n",
    "df3b.reset_index(drop=True, inplace=True)\n",
    "df3b['job_seniority']=0\n",
    "for index in range(len(df3b)):\n",
    "    df3b.loc[index,'job_seniority'] = 'junior' if df3b.loc[index,'sen_nonexecutive'] == 1 else (\n",
    "                                  'junior' if df3b.loc[index,'sen_juniorexecutive'] == 1 else (\n",
    "                                  'junior' if df3b.loc[index,'sen_executive'] == 1 else (\n",
    "                                  'junior' if df3b.loc[index,'sen_seniorexecutive'] == 1 else (\n",
    "                                  'junior' if df3b.loc[index,'sen_freshentrylevel'] == 1 else (\n",
    "                                  'junior' if df3b.loc[index,'sen_professional'] == 1 else (\n",
    "                                  'senior' if df3b.loc[index,'sen_manager'] == 1 else (\n",
    "                                  'senior' if df3b.loc[index,'sen_middlemanagement'] == 1 else (\n",
    "                                  'senior' if df3b.loc[index,'sen_seniormanagement'] == 1 else (0\n",
    "                                  )))))))))\n",
    "\n",
    "print('baseline accuracy: {:.6f}'.format(np.max(df3b.job_seniority.value_counts())/len(df3b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.775641\n"
     ]
    }
   ],
   "source": [
    "# using skills required to predict job seniority\n",
    "cols = [i for i in df3a.columns if ( ('skill_' in i) )]\n",
    "X3b = df3b[cols]\n",
    "y3b = df3b['job_seniority']\n",
    "X3b_train, X3b_test, y3b_train, y3b_test = train_test_split(X3b, y3b, test_size=0.2, random_state=42)\n",
    "# use logistic regression to predict\n",
    "logreg3b = LogisticRegression(solver='lbfgs', multi_class='auto').fit(X3b_train, y3b_train)\n",
    "y3b_pred = logreg3b.predict(X3b_test)\n",
    "# get accuracy of prediction\n",
    "print('Accuracy: {:.6f}'.format(metrics.accuracy_score(y3b_test, y3b_pred)) )\n",
    "# score of 0.776 is better than baseline (0.704). model is useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.846154\n"
     ]
    }
   ],
   "source": [
    "# using job title to predict job seniority\n",
    "X3b = df3b['job_title']\n",
    "y3b = df3b['job_seniority']\n",
    "\n",
    "X3b_train, X3b_test, y3b_train, y3b_test = train_test_split(X3b, y3b, test_size=0.3, random_state=42)\n",
    "\n",
    "# create model\n",
    "model3b = make_pipeline( CountVectorizer(stop_words='english', \n",
    "                        ngram_range=(1,5), \n",
    "                        max_features=1000,\n",
    "                        min_df=1),\n",
    "                      \n",
    "                        MultinomialNB()\n",
    "                      )\n",
    "# fit & predict data\n",
    "model3b.fit(X3b_train, y3b_train)\n",
    "y3b_pred = model3b.predict(X3b_test)\n",
    "\n",
    "# present results\n",
    "print('Accuracy: {:.6f}'.format(metrics.accuracy_score(y3b_test, y3b_pred)) )\n",
    "# score of 0.846 is better than previous model score (0.776). this model is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 30 characteristics in a job title that makes Senior role different from others roles are: \n",
      "['hadoop' 'principal business' 'principal infocomm'\n",
      " 'principal infocomm specialist' 'principal infocomm specialist data'\n",
      " 'principal infocomm specialist data analytics'\n",
      " 'manager 3500 5500 days river' 'manager 3500 5500 days'\n",
      " 'manager 3500 5500' 'manager 3500' 'principal software'\n",
      " 'principal software engineering' 'principal software engineering lead'\n",
      " 'processing' 'processing executive' 'procurement' 'machine learning'\n",
      " 'machine' 'procurement business' 'procurement business intelligence'\n",
      " 'procurement business intelligence 19001366' 'procurement executive'\n",
      " 'level data scientist' 'level data engineer' 'level data' 'level'\n",
      " 'lecturer' 'learning i2r star' 'learning i2r' 'learning engineer']\n"
     ]
    }
   ],
   "source": [
    "results_3b = pd.DataFrame([model3b.steps[1][1].coef_[0]],\n",
    "                         columns = model3b.steps[0][1].get_feature_names()).transpose()\n",
    "\n",
    "null_cols = results_3b[results_3b[0]==0].index\n",
    "results_3b = results_3b.transpose()\n",
    "results_3b.drop(columns = null_cols, inplace=True)\n",
    "\n",
    "results_3b = results_3b.transpose()\n",
    "results_3b.columns = ['coef']\n",
    "results_3b['abs_coef'] = np.abs(results_3b.coef)\n",
    "results_3b['weightage'] = results_3b.coef / np.sum(results_3b.coef)\n",
    "results_3b['abs_weightage'] = results_3b.abs_coef / np.sum(results_3b.abs_coef)\n",
    "\n",
    "# results_3b.sort_values(by='abs_weightage', ascending = False, inplace = True )\n",
    "results_3b.sort_values(by='abs_weightage', ascending = False, inplace = True)\n",
    "num_results = 30\n",
    "# print(results_3b.head(num_results))\n",
    "\n",
    "\n",
    "print('The top {} characteristics in a job title \\\n",
    "that makes Senior role different from others roles are: \\n{}'.format(num_results,\n",
    "                                                                     results_3b.head(num_results).index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "      <th>weightage</th>\n",
       "      <th>abs_weightage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hadoop</th>\n",
       "      <td>-7.749322</td>\n",
       "      <td>7.749322</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>principal business</th>\n",
       "      <td>-7.749322</td>\n",
       "      <td>7.749322</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>principal infocomm</th>\n",
       "      <td>-7.749322</td>\n",
       "      <td>7.749322</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>principal infocomm specialist</th>\n",
       "      <td>-7.749322</td>\n",
       "      <td>7.749322</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>principal infocomm specialist data</th>\n",
       "      <td>-7.749322</td>\n",
       "      <td>7.749322</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>principal infocomm specialist data analytics</th>\n",
       "      <td>-7.749322</td>\n",
       "      <td>7.749322</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manager 3500 5500 days river</th>\n",
       "      <td>-7.749322</td>\n",
       "      <td>7.749322</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manager 3500 5500 days</th>\n",
       "      <td>-7.749322</td>\n",
       "      <td>7.749322</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manager 3500 5500</th>\n",
       "      <td>-7.749322</td>\n",
       "      <td>7.749322</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manager 3500</th>\n",
       "      <td>-7.749322</td>\n",
       "      <td>7.749322</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  coef  abs_coef  weightage  \\\n",
       "hadoop                                       -7.749322  7.749322   0.001076   \n",
       "principal business                           -7.749322  7.749322   0.001076   \n",
       "principal infocomm                           -7.749322  7.749322   0.001076   \n",
       "principal infocomm specialist                -7.749322  7.749322   0.001076   \n",
       "principal infocomm specialist data           -7.749322  7.749322   0.001076   \n",
       "principal infocomm specialist data analytics -7.749322  7.749322   0.001076   \n",
       "manager 3500 5500 days river                 -7.749322  7.749322   0.001076   \n",
       "manager 3500 5500 days                       -7.749322  7.749322   0.001076   \n",
       "manager 3500 5500                            -7.749322  7.749322   0.001076   \n",
       "manager 3500                                 -7.749322  7.749322   0.001076   \n",
       "\n",
       "                                              abs_weightage  \n",
       "hadoop                                             0.001076  \n",
       "principal business                                 0.001076  \n",
       "principal infocomm                                 0.001076  \n",
       "principal infocomm specialist                      0.001076  \n",
       "principal infocomm specialist data                 0.001076  \n",
       "principal infocomm specialist data analytics       0.001076  \n",
       "manager 3500 5500 days river                       0.001076  \n",
       "manager 3500 5500 days                             0.001076  \n",
       "manager 3500 5500                                  0.001076  \n",
       "manager 3500                                       0.001076  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_3b.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# section 3c: do the requirements for titles vary significantly\n",
    "# with industry (e.g. healthcare vs government)\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 0.500000\n"
     ]
    }
   ],
   "source": [
    "# extract the indices of rows with \"manager\" in job title\n",
    "jobs.reset_index(drop=True, inplace=True)\n",
    "manager_index = jobs[jobs['job_title'].str.contains('Manager')].index\n",
    "\n",
    "# copy out the dataframe\n",
    "df3c = jobs.loc[manager_index,:]\n",
    "\n",
    "healthcare_index = df3c[df3c['cat_healthcarepharmaceutical']==1].index\n",
    "gov_index = df3c[df3c['cat_publiccivilservice']==1].index\n",
    "\n",
    "# as the data is inbalanced, we extract an equal number of samples from each class\n",
    "np.random.seed(42)\n",
    "df3c_index = np.append(np.random.choice(healthcare_index,size=500, replace=True), \n",
    "                       np.random.choice(gov_index, size=500, replace=True))\n",
    "# create the balanced dataframe\n",
    "df3c = df3c.loc[df3c_index,:].reset_index(drop=True)\n",
    "\n",
    "# check if there is any jobs that falls under both category\n",
    "if (df3c[['cat_publiccivilservice','cat_healthcarepharmaceutical']].sum(axis=1).value_counts()[1]) != 1000:\n",
    "    print('ERROR: Data contains jobs with two classes')\n",
    "    \n",
    "print('baseline accuracy: {:.6f}'.format(np.max(df3c.cat_publiccivilservice.value_counts())/len(df3c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the skill required for a manager in public service vs healthcare\n",
    "# if the manager skills can determine if public service or healthcare,\n",
    "# then the requirement of titles does differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.896667\n"
     ]
    }
   ],
   "source": [
    "# create predictor and target matrix\n",
    "skill_cols = [col for col in df3c.columns if 'skill_' in col]\n",
    "X3c = df3c[skill_cols]\n",
    "y3c = df3c['cat_publiccivilservice']\n",
    "\n",
    "X3c_train, X3c_test, y3c_train, y3c_test = train_test_split(X3c, y3c, test_size=0.3, random_state = 42)\n",
    "\n",
    "logreg3c = LogisticRegression(solver = 'lbfgs').fit(X3c_train, y3c_train)\n",
    "y3c_pred = logreg3c.predict(X3c_test)\n",
    "print('Accuracy: {:.6f}'.format(metrics.accuracy_score(y3c_test, y3c_pred)) )\n",
    "# model score of 0.897 is better than baseline score of 0.5. model is good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 characteristics that makes manager working for the Government (Civil/Public Service) different from manager working for Healthcare are: \n",
      "['skill_budgets' 'skill_construction' 'skill_sql' 'skill_databases'\n",
      " 'skill_edc' 'skill_research' 'skill_gcp' 'skill_access' 'skill_html'\n",
      " 'skill_visio']\n"
     ]
    }
   ],
   "source": [
    "results_3c = pd.DataFrame([logreg3c.coef_[0]], columns=skill_cols).transpose()\n",
    "null_cols = results_3c[results_3c[0]==0].index\n",
    "results_3c = results_3c.transpose()\n",
    "results_3c.drop(columns=null_cols, inplace=True)\n",
    "\n",
    "results_3c = results_3c.transpose()\n",
    "results_3c.columns = ['coef']\n",
    "results_3c['abs_coef'] = np.abs(results_3c.coef)\n",
    "results_3c['weightage'] = results_3c.coef / np.sum(results_3c.coef)\n",
    "results_3c['abs_weightage'] = results_3c.abs_coef / np.sum(results_3c.abs_coef)\n",
    "# results_3c.sort_values(by='abs_weightage', ascending = False, inplace = True )\n",
    "results_3c.sort_values(by='weightage', ascending = False, inplace = True)\n",
    "num_results = 10\n",
    "# print(results_3c.head(num_results))\n",
    "\n",
    "print('The top {} characteristics that makes manager working for the Government (Civil/Public Service) \\\n",
    "different from manager working for Healthcare are: \\n{}'.format(\n",
    "      num_results, results_3c.head(num_results).index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "      <th>weightage</th>\n",
       "      <th>abs_weightage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>skill_budgets</th>\n",
       "      <td>-1.325162</td>\n",
       "      <td>1.325162</td>\n",
       "      <td>0.228439</td>\n",
       "      <td>0.052966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_construction</th>\n",
       "      <td>-1.325162</td>\n",
       "      <td>1.325162</td>\n",
       "      <td>0.228439</td>\n",
       "      <td>0.052966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_sql</th>\n",
       "      <td>-1.247226</td>\n",
       "      <td>1.247226</td>\n",
       "      <td>0.215004</td>\n",
       "      <td>0.049851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_databases</th>\n",
       "      <td>-1.247226</td>\n",
       "      <td>1.247226</td>\n",
       "      <td>0.215004</td>\n",
       "      <td>0.049851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_edc</th>\n",
       "      <td>-1.197099</td>\n",
       "      <td>1.197099</td>\n",
       "      <td>0.206363</td>\n",
       "      <td>0.047848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_research</th>\n",
       "      <td>-1.197099</td>\n",
       "      <td>1.197099</td>\n",
       "      <td>0.206363</td>\n",
       "      <td>0.047848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_gcp</th>\n",
       "      <td>-1.197099</td>\n",
       "      <td>1.197099</td>\n",
       "      <td>0.206363</td>\n",
       "      <td>0.047848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_access</th>\n",
       "      <td>-0.946142</td>\n",
       "      <td>0.946142</td>\n",
       "      <td>0.163102</td>\n",
       "      <td>0.037817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_html</th>\n",
       "      <td>-0.946142</td>\n",
       "      <td>0.946142</td>\n",
       "      <td>0.163102</td>\n",
       "      <td>0.037817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_visio</th>\n",
       "      <td>-0.946142</td>\n",
       "      <td>0.946142</td>\n",
       "      <td>0.163102</td>\n",
       "      <td>0.037817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        coef  abs_coef  weightage  abs_weightage\n",
       "skill_budgets      -1.325162  1.325162   0.228439       0.052966\n",
       "skill_construction -1.325162  1.325162   0.228439       0.052966\n",
       "skill_sql          -1.247226  1.247226   0.215004       0.049851\n",
       "skill_databases    -1.247226  1.247226   0.215004       0.049851\n",
       "skill_edc          -1.197099  1.197099   0.206363       0.047848\n",
       "skill_research     -1.197099  1.197099   0.206363       0.047848\n",
       "skill_gcp          -1.197099  1.197099   0.206363       0.047848\n",
       "skill_access       -0.946142  0.946142   0.163102       0.037817\n",
       "skill_html         -0.946142  0.946142   0.163102       0.037817\n",
       "skill_visio        -0.946142  0.946142   0.163102       0.037817"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_3c.head(num_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
